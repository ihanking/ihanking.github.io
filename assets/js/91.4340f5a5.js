(window.webpackJsonp=window.webpackJsonp||[]).push([[91],{571:function(s,t,a){"use strict";a.r(t);var n=a(4),r=Object(n.a)({},(function(){var s=this,t=s.$createElement,a=s._self._c||t;return a("ContentSlotsDistributor",{attrs:{"slot-key":s.$parent.slotKey}},[a("h2",{attrs:{id:"简介"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#简介"}},[s._v("#")]),s._v(" 简介")]),s._v(" "),a("p",[s._v("什么是KNN算法，这里引用百度百科的解释")]),s._v(" "),a("blockquote",[a("p",[s._v("邻近算法，或者说K最近邻（KNN，K-NearestNeighbor）分类算法是数据挖掘分类技术中最简单的方法之一。所谓K最近邻，就是K个最近的邻居的意思，说的是每个样本都可以用它最接近的K个邻近值来代表。近邻算法就是将数据集合中每一个记录进行分类的方法。")])]),s._v(" "),a("p",[a("strong",[s._v("举例")])]),s._v(" "),a("p",[s._v("有一句老话叫作“物以类聚、人以群分”。想象我们在一个特别的社区里，一条清澈的小河从社区中心流过，小河左侧环境优美，住着一群有钱人，家家户户都是别墅；而小河的另一侧，住着大片贫民，用茅草和纸板搭建的临时住所密密麻麻的。")]),s._v(" "),a("p",[s._v("这时有一个新的住户从外面搬进了这个社区，他住在了小河的左侧，此时社区里就传开了消息：“我们这又搬来了一户有钱人家。”可是谁都不认识他，也看不到他的银行账户，为什么就认定他是有钱人呢？那是因为他跟有钱人住在一起了。故事到了这里，也就说明了最近邻算法的思路：“你跟谁住得近，你就跟谁是同一类”。")]),s._v(" "),a("h2",{attrs:{id:"原理"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#原理"}},[s._v("#")]),s._v(" 原理")]),s._v(" "),a("p",[s._v("有了思路，我们再来看看原理，KNN 算法是如何处理的。用一句话来解释 KNN 算法原理，那就是找到 K 个与新数据最近的样本，取样本中最多的一个类别作为新数据的类别。在前面的例子中，找到和新搬进来的一户人家住的"),a("strong",[s._v("距离最近")]),s._v("的 K 户人家，看看 K 户人家中是有钱人多还是穷人多，取多的那个类别作为新搬来这户的类别。所以，显然他住在富人区，那附近就会有更多的富人。")]),s._v(" "),a("p",[s._v("这里面我们提到了一个"),a("strong",[s._v("距离最近")]),s._v("，关于距离该怎么计算呢？最常见的一个计算方法就是"),a("strong",[s._v("欧式距离")]),s._v("，即两点之间的连线，如果放在地图上就是两个房子的直线距离。当然除了欧式距离，还有很多距离计算的方式，比如"),a("strong",[s._v("曼哈顿距离")]),s._v("、"),a("strong",[s._v("切比雪夫距离")]),s._v("等。")]),s._v(" "),a("p",[a("img",{attrs:{src:"/images/202009/19/knn%E7%AE%97%E6%B3%95.jpg",alt:"knn算法"}})]),s._v(" "),a("h2",{attrs:{id:"流程"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#流程"}},[s._v("#")]),s._v(" 流程")]),s._v(" "),a("p",[s._v("总体来说，KNN分类算法包括以下4个步骤：")]),s._v(" "),a("ol",[a("li",[a("p",[s._v("准备数据，对数据进行预处理")])]),s._v(" "),a("li",[a("p",[s._v("计算测试样本点（也就是待分类点）到其他每个样本点的距离")])]),s._v(" "),a("li",[a("p",[s._v("对每个距离进行排序，然后选择出距离最小的K个点")])]),s._v(" "),a("li",[a("p",[s._v("对K个点所属的类别进行比较，根据少数服从多数的原则，将测试样本点归入在K个点中占比最高的那一类")])])]),s._v(" "),a("h2",{attrs:{id:"优缺点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#优缺点"}},[s._v("#")]),s._v(" 优缺点")]),s._v(" "),a("h3",{attrs:{id:"优点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#优点"}},[s._v("#")]),s._v(" 优点")]),s._v(" "),a("p",[a("strong",[s._v("简单易实现")]),s._v("： 刚把 KNN 算法介绍完了，是不是很简单？从上面的内容可以看出来，KNN 算法最后实际上并没有抽象出任何模型，而是把全部的数据集直接当作模型本身，当一条新数据来了之后跟数据集里面的每一条数据进行对比。")]),s._v(" "),a("p",[s._v("所以可以看到 KNN 算法的一些优点，首当其冲的就是这个算法简单，简单到都不需要进行什么训练了，只要把样本数据整理好了，就结束了，来一条新数据就可以进行预测了。")]),s._v(" "),a("p",[a("strong",[s._v("对于边界不规则的数据效果较好")]),s._v("： 可以想到，我们最终的预测是把未知数据作为中心点，然后画一个圈，使得圈里有 K 个数据，所以对于边界不规则的数据，要比线性的分类器效果更好。因为线性分类器可以理解成画一条线来分类，不规则的数据则很难找到一条线将其分成左右两边。")]),s._v(" "),a("h3",{attrs:{id:"缺点"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#缺点"}},[s._v("#")]),s._v(" 缺点")]),s._v(" "),a("p",[a("strong",[s._v("只适合小数据集")]),s._v("： 正是因为这个算法太简单，每次预测新数据都需要使用全部的数据集，所以如果数据集太大，就会消耗非常长的时间，占用非常大的存储空间。")]),s._v(" "),a("p",[a("strong",[s._v("数据不平衡效果不好")]),s._v("： 如果数据集中的数据不平衡，有的类别数据特别多，有的类别数据特别少，那么这种方法就会失效了，因为特别多的数据最后在投票的时候会更有竞争优势。")]),s._v(" "),a("p",[a("strong",[s._v("必须要做数据标准化")]),s._v("： 由于使用距离来进行计算，如果数据量纲不同，数值较大的字段影响就会变大，所以需要对数据进行标准化，比如都转换到 0-1 的区间。")]),s._v(" "),a("p",[a("strong",[s._v("不适合特征维度太多的数据")]),s._v("： 由于我们只能处理小数据集，如果数据的维度太多，那么样本在每个维度上的分布就很少。比如我们只有三个样本，每个样本只有一个维度，这比每个样本有三个维度特征要明显很多。")]),s._v(" "),a("h2",{attrs:{id:"关于k的选取"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#关于k的选取"}},[s._v("#")]),s._v(" 关于K的选取")]),s._v(" "),a("p",[s._v("K 值的选取会影响到模型的效果。在极端情况下，如果 K 取 1，由于富人区人均面积都很大，家里可能是别墅加后花园，富人与富人房子的距离相对较远，那个恰好住在河边的人可能跟河对面的一户贫民家最近，那么这个新人就会被判定为贫民。")]),s._v(" "),a("p",[s._v("如果 K 取值与数据集的大小一样，那么也可想而知，由于贫民的人数户数都远远多于富人，那么所有新进来的人，不管他住哪里都会被判定为贫民。这种情况下，最终结果就是整个样本中占多数的分类的结果，这个模型也就没有什么作用了。")]),s._v(" "),a("p",[s._v("用我们前面学过的内容来看，当K 越小的时候容易过拟合，因为结果的判断与某一个点强相关。而K 越大的时候容易欠拟合，因为要考虑所有样本的情况，那就等于什么都不考虑。")]),s._v(" "),a("p",[s._v("对于 K 的取值，一种显而易见的办法就是从 1 开始不断地尝试，查看准确率。随着 K 的增加，一般情况下准确率会先变大后变小，然后选取效果最好的那个 K 值就好了。当然，关于 K 最好使用奇数，因为偶数在投票的时候就困难了，如果两个类别的投票数量是一样的，那就没办法抉择了，只能随机选一个。")]),s._v(" "),a("p",[s._v("所以选取一个合适的 K 值也是 KNN 算法在实现时候的一个难点，需要根据经验和效果去进行尝试。")]),s._v(" "),a("h2",{attrs:{id:"实例"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#实例"}},[s._v("#")]),s._v(" 实例")]),s._v(" "),a("p",[s._v("使用鸢尾花数据集作实践例子")]),s._v(" "),a("p",[s._v("首先是导入我们所需要的依赖库：")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sklearn的数据集")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" datasets\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#sklearn模块的KNN类")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("from")]),s._v(" sklearn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("neighbors "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" KNeighborsClassifier\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#矩阵运算库numpy")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("import")]),s._v(" numpy "),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("as")]),s._v(" np\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#设置随机种子，不设置的话默认是按系统时间作为参数，设置后可以保证我们每次产生的随机数是一样的")]),s._v("\nnp"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("seed"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("0")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br")])]),a("p",[s._v("在这里我们使用一个叫作鸢尾花数据集的数据，这个数据集里面有 150 条数据，共有 3 个类别，即 Setosa 鸢尾花、Versicolour 鸢尾花和 Virginica 鸢尾花，每个类别有 50 条数据，每条数据有 4 个维度，分别记录了鸢尾花的花萼长度、花萼宽度、花瓣长度和花瓣宽度。")]),s._v(" "),a("div",{staticClass:"language-python line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-python"}},[a("code",[s._v("iris"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("datasets"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("load_iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#获取鸢尾花数据集")]),s._v("\niris_x"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("data"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#数据部分")]),s._v("\niris_y"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("iris"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("target"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#类别部分")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#从150条数据中选140条作为训练集，10条作为测试集。permutation 接收一个数作为参数(这里为数据集长度150),产生一个0-149乱序一维数组")]),s._v("\nrandomarr"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" np"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("random"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("permutation"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token builtin"}},[s._v("len")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\niris_x_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" iris_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("randomarr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#训练集数据")]),s._v("\niris_y_train "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" iris_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("randomarr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#训练集标签")]),s._v("\niris_x_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" iris_x"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("randomarr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#测试集数据")]),s._v("\niris_y_test "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" iris_y"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("randomarr"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("10")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(":")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),s._v(" "),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#测试集标签")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#定义一个knn分类器对象")]),s._v("\nknn "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" KNeighborsClassifier"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#调用该对象的训练方法，主要接收两个参数：训练数据集及其类别标签")]),s._v("\nknn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("fit"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_x_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v(" iris_y_train"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#调用预测方法，主要接收一个参数：测试数据集")]),s._v("\niris_y_predict "),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v(" knn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#计算各测试样本预测的概率值 这里我们没有用概率值，但是在实际工作中可能会参考概率值来进行最后结果的筛选，而不是直接使用给出的预测标签")]),s._v("\nprobility"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("knn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("predict_proba"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#计算与最后一个测试样本距离最近的5个点，返回的是这些样本的序号组成的数组")]),s._v("\nneighborpoint"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("knn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("kneighbors"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),s._v("iris_x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("[")]),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("-")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("1")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("]")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),a("span",{pre:!0,attrs:{class:"token number"}},[s._v("5")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#调用该对象的打分方法，计算出准确率")]),s._v("\nscore"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),s._v("knn"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(".")]),s._v("score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_x_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("iris_y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("sample_weight"),a("span",{pre:!0,attrs:{class:"token operator"}},[s._v("=")]),a("span",{pre:!0,attrs:{class:"token boolean"}},[s._v("None")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#输出测试的结果")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'iris_y_predict = '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_y_predict"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#输出原始测试数据集的正确标签，以方便对比")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'iris_y_test = '")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),s._v("iris_y_test"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[s._v("#输出准确率计算结果")]),s._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[s._v("print")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v("(")]),a("span",{pre:!0,attrs:{class:"token string"}},[s._v("'Accuracy:'")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(",")]),s._v("score"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[s._v(")")]),s._v("\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br"),a("span",{staticClass:"line-number"},[s._v("6")]),a("br"),a("span",{staticClass:"line-number"},[s._v("7")]),a("br"),a("span",{staticClass:"line-number"},[s._v("8")]),a("br"),a("span",{staticClass:"line-number"},[s._v("9")]),a("br"),a("span",{staticClass:"line-number"},[s._v("10")]),a("br"),a("span",{staticClass:"line-number"},[s._v("11")]),a("br"),a("span",{staticClass:"line-number"},[s._v("12")]),a("br"),a("span",{staticClass:"line-number"},[s._v("13")]),a("br"),a("span",{staticClass:"line-number"},[s._v("14")]),a("br"),a("span",{staticClass:"line-number"},[s._v("15")]),a("br"),a("span",{staticClass:"line-number"},[s._v("16")]),a("br"),a("span",{staticClass:"line-number"},[s._v("17")]),a("br"),a("span",{staticClass:"line-number"},[s._v("18")]),a("br"),a("span",{staticClass:"line-number"},[s._v("19")]),a("br"),a("span",{staticClass:"line-number"},[s._v("20")]),a("br"),a("span",{staticClass:"line-number"},[s._v("21")]),a("br"),a("span",{staticClass:"line-number"},[s._v("22")]),a("br"),a("span",{staticClass:"line-number"},[s._v("23")]),a("br"),a("span",{staticClass:"line-number"},[s._v("24")]),a("br"),a("span",{staticClass:"line-number"},[s._v("25")]),a("br"),a("span",{staticClass:"line-number"},[s._v("26")]),a("br"),a("span",{staticClass:"line-number"},[s._v("27")]),a("br"),a("span",{staticClass:"line-number"},[s._v("28")]),a("br"),a("span",{staticClass:"line-number"},[s._v("29")]),a("br")])]),a("p",[s._v("结果如下：")]),s._v(" "),a("div",{staticClass:"language- line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[s._v("iris_y_predict = \n[2 1 2 0 1 1 0 1 2 2]\niris_y_test = \n[2 1 2 0 1 2 0 1 2 2]\nAccuracy: 0.9\n")])]),s._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[s._v("1")]),a("br"),a("span",{staticClass:"line-number"},[s._v("2")]),a("br"),a("span",{staticClass:"line-number"},[s._v("3")]),a("br"),a("span",{staticClass:"line-number"},[s._v("4")]),a("br"),a("span",{staticClass:"line-number"},[s._v("5")]),a("br")])]),a("p",[s._v("可以看到，该模型的准确率为0.9，其中第二个数据预测错误了。")])])}),[],!1,null,null,null);t.default=r.exports}}]);