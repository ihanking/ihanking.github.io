(window.webpackJsonp=window.webpackJsonp||[]).push([[91],{571:function(v,t,_){"use strict";_.r(t);var e=_(4),i=Object(e.a)({},(function(){var v=this,t=v.$createElement,_=v._self._c||t;return _("ContentSlotsDistributor",{attrs:{"slot-key":v.$parent.slotKey}},[_("ul",[_("li",[_("p",[v._v("数据预处理（清洗）的基操以及优缺点。")])]),v._v(" "),_("li",[_("p",[v._v("特征工程，如归一化，类别特征处理，高维组合特征处理，Word2Vec等。")])]),v._v(" "),_("li",[_("p",[v._v("模型评估，如过拟合和欠拟合，超参数调优，模型评估指标以及调优等。")])]),v._v(" "),_("li",[_("p",[v._v("典型算法的原理及应用，优缺点（SVM，决策树，RF，Xgb，lgb，catboost等）。")])]),v._v(" "),_("li",[_("p",[v._v("神经网络种类，原理，调参等。")])]),v._v(" "),_("li",[_("p",[v._v("优化算法如有监督学习的损失函数，经典优化算法，梯度验证，随机梯度下降及其加速，L1\\L2正则化与稀疏等。")])]),v._v(" "),_("li",[_("p",[v._v("集成学习如boosting和bagging等。")])])]),v._v(" "),_("h3",{attrs:{id:"十大算法系列"}},[_("a",{staticClass:"header-anchor",attrs:{href:"#十大算法系列"}},[v._v("#")]),v._v(" 十大算法系列")]),v._v(" "),_("p",[v._v("1.线性回归 (Linear Regression)")]),v._v(" "),_("p",[v._v("2.逻辑回归 (Logistic Regression)")]),v._v(" "),_("p",[v._v("3.决策树 (Decision Tree)")]),v._v(" "),_("p",[v._v("4.支持向量机（SVM）")]),v._v(" "),_("p",[v._v("5.朴素贝叶斯 (Naive Bayes)")]),v._v(" "),_("p",[v._v("6.K邻近算法（KNN）")]),v._v(" "),_("p",[v._v("7.K-均值算法（K-means）")]),v._v(" "),_("p",[v._v("8.随机森林 (Random Forest)")]),v._v(" "),_("p",[v._v("9.降低维度算法（Dimensionality Reduction Algorithms）")]),v._v(" "),_("p",[v._v("10.Gradient Boost和Adaboost算法")])])}),[],!1,null,null,null);t.default=i.exports}}]);