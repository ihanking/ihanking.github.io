---
title: 网剧《隐秘的角落》豆瓣评论数据分析
date: 2020-09-27
draft: false
tags: ["requests","pandas"]
categories: ["分析实战"]
---

最近网剧《隐秘的角落》火热，豆瓣评分挺高

![隐秘的角落评分](/images/202009/22/隐秘的角落评分.jpg)

接下来就网友对这部剧的评论和看法，进行简单的分析

## 数据获取

首先从豆瓣评论页面后台入口抓取网友的评论信息

隐秘的角落：`https://movie.douban.com/subject/33404425/comments?start=20&limit=20&sort=new_score&status=P&comments_only=1`

## 数据读取

```python
# 导入所需包
import numpy as np
import pandas as pd
import re
import jieba

from pyecharts.charts import Pie, Bar, Map, Line, Page
from pyecharts import options as opts
from pyecharts.globals import SymbolType, WarningType
WarningType.ShowWarning = False
pd.options.display.max_rows = 1000
```

```python
# 读入数据
df = pd.read_excel('./data/隐秘的角落豆瓣短评6.26.xlsx')
print(df.shape)
print(df.info())
```
```
(500, 7)
<class 'pandas.core.frame.DataFrame'>
RangeIndex: 500 entries, 0 to 499
Data columns (total 7 columns):
 #   Column         Non-Null Count  Dtype 
---  ------         --------------  ----- 
 0   user_name      500 non-null    object
 1   page_url       500 non-null    object
 2   rating_num     500 non-null    object
 3   comment_time   500 non-null    object
 4   short_comment  500 non-null    object
 5   votes_num      500 non-null    int64 
 6   city_name      500 non-null    object
dtypes: int64(1), object(6)
memory usage: 27.5+ KB
None
```
```python
# 删除列
df = df.drop('page_url', axis=1)

# 查看重复值和空值
print(df.duplicated().sum())
print(df.isnull().sum())
```
```
0
user_name        0
rating_num       0
comment_time     0
short_comment    0
votes_num        0
city_name        0
dtype: int64
```

## 数据预处理

1. rating_num: 异常值处理、星级转换
2. comment_time: 时间类型转换
3. short_comment：分词处理
4. city_name：提取城市名

```python
# 定义字典
def transform_rating(x):
    if x == '立荐':
        return '5星'
    elif x == '推荐':
        return '4星'
    elif x == '还行':
        return '3星'
    elif x == '较差':
        return '2星'
    elif x == '很差':
        return '1星'
    else:
        return '5星'  # 异常值使用众数替换

# apply函数
df['rating_num'] = df.rating_num.apply(transform_rating) 
df.rating_num.value_counts() 
```
```
5星    272
4星    117
3星     63
2星     38
1星     10
Name: rating_num, dtype: int64
```

```python
# 城市数据处理
# 国外数据
df['city_name'] = df['city_name'].map(lambda x:'国外' if re.search('[a-zA-Z]', x) else x)

# 处理国内数据
def tranform_city(x):
    if '中国香港' in x:
        return '香港' 
    elif '中国澳门' in x:
        return '澳门' 
    elif '河北' in x:
        return '河北'
    elif '青铜峡' in x:
        return '宁夏'
    elif '江苏' in x:
        return '江苏' 
    elif len(x) == 4 and '中国' not in x:
        return x[:2]
    elif len(x) > 4:
        return x[:3]
    else:
        return x
    
# apply函数
df['city_name'] = df.city_name.apply(tranform_city)
```

## 数据可视化

### 总体评分分布

```python
rating_num = df.rating_num.value_counts() 
rating_num
```
```
5星    272
4星    117
3星     63
2星     38
1星     10
Name: rating_num, dtype: int64
```

```python
# 数据对
data_pair = [list(z) for z in zip(rating_num.index.tolist(), rating_num.values.tolist())]

# 绘制饼图
pie1 = Pie(init_opts=opts.InitOpts(width='1350px', height='750px'))
pie1.add('', data_pair=data_pair, radius=['35%', '60%'], rosetype='radius')
pie1.set_global_opts(title_opts=opts.TitleOpts(title='总体评分分布'), 
#                      toolbox_opts=opts.ToolboxOpts(),
                     legend_opts=opts.LegendOpts(orient='vertical', pos_top='15%', pos_left='2%'))
pie1.set_series_opts(label_opts=opts.LabelOpts(formatter="{b}:{d}%"))
pie1.set_colors(['#FF7F0E', '#1F77B4', '#2CA02C', '#D62728', '#946C8B'])
#pie1.render()
pie1.render_notebook()
```
![隐秘总体评分分布](/images/202009/28/隐秘总体评分分布.jpg)

### 评论时间走势

```python
comment_hour = df.comment_time.str.split(':').str[0]
comment_hour = comment_hour.value_counts().sort_index()
comment_hour[:5] 
```
```
2020-06-16 20    20
2020-06-16 21    31
2020-06-16 22    29
2020-06-16 23    17
2020-06-17 00     8
Name: comment_time, dtype: int64
```

```python
# 选取数据
x_data = [i.replace('2020-','') for i in comment_hour.index]
y_data = comment_hour.values.tolist()

# 折线图
line1 = Line(init_opts=opts.InitOpts(width='1350px', height='750px'))
line1.add_xaxis(x_data)
line1.add_yaxis('', y_data,
                areastyle_opts=opts.AreaStyleOpts(opacity=0.5),
                markpoint_opts=opts.MarkPointOpts(data=[opts.MarkPointItem(type_="max")]),
                label_opts=opts.LabelOpts(is_show=False)
               )
line1.set_global_opts(title_opts=opts.TitleOpts(title='评论数量时间走势图'), 
                      xaxis_opts=opts.AxisOpts(axislabel_opts=opts.LabelOpts(rotate='90')),
                      visualmap_opts=opts.VisualMapOpts(max_=30))
line1.set_series_opts(linestyle_opts=opts.LineStyleOpts(width=3))
line1.render()
```
![隐秘评论数量时间走势](/images/202009/28/隐秘评论数量时间走势.jpg)

### 分词

数据抓取下来后，对评论信息进行分词处理

```python
import pandas as pd

data=pd.read_excel("data.xlsx")

txt = data['Content'].str.cat(sep='。')

# 文本预处理  去除一些无用的字符   只提取出中文出来
new_data = re.findall('[\u4e00-\u9fa5]+', txt, re.S)  # 只要字符串中的中文
new_data = " ".join(new_data)

# 文本分词--精确模式
seg_list_exact = jieba.cut(new_data, cut_all=False)

result_list = []
with open('stop_words.txt', encoding='utf-8') as f:
    con = f.readlines()
    stop_words = set()
    for i in con:
        i = i.replace("\n", "")   # 去掉读取每一行数据的\n
        stop_words.add(i)

for word in seg_list_exact:
    # 设置停用词并去除单个词
    if word not in stop_words and len(word) > 1:
        result_list.append(word)
# print(result_list)

# 筛选后统计
word_counts = collections.Counter(result_list)
# 获取前100最高频的词
word_counts_top100 = word_counts.most_common(100)
# 打印出来看看统计的词频
# print(word_counts_top100)
```

## 词云图

最后进行词云图展示

![隐秘的角落](/images/202009/22/隐秘的角落词云图.jpg)