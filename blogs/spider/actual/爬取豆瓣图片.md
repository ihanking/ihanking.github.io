---
title: 爬虫实战|爬取豆瓣图片
date: 2020-10-23
draft: false
tags: ["requests"]
categories: ["爬虫系列"]
---

```python
import time
import json
import shutil
import random
import requests
import re,os,csv
import traceback
import pandas as pd
from lxml import etree
from loguru import logger
from parsel import Selector
from urllib.parse import urljoin
from dataclasses import dataclass
from copyheaders import headers_raw_to_dict
session=requests.Session()
requests.packages.urllib3.disable_warnings()

@dataclass
class Spider(object):
    sku = os.path.splitext(os.path.basename(__file__))[0]
    r_h=b'''
    Cookie: ll="118282"; bid=Y4AaDkvtfWE; push_doumail_num=0; _vwo_uuid_v2=D2D3B78CE0D3669489E8C20AD4EBECC14|3133ccb1635f05428c1b1e0aa53ba021; gr_user_id=1514c998-7897-4978-b145-e5b90b112d79; douban-fav-remind=1; __gads=ID=f6bc8931e52455db:T=1589027862:S=ALNI_Mbiipw8JRVJFHZgcpqW7GHkJhKfag; douban-profile-remind=1; __utmv=30149280.14155; viewed="34463395"; push_noty_num=0; ct=y; __utmz=223695111.1603011421.47.37.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; dbcl2="141551961:DE8/jNURItU"; __utmz=30149280.1603274659.47.20.utmcsr=baidu|utmccn=(organic)|utmcmd=organic; ck=ZlnW; ap_v=0,6.0; _pk_ref.100001.4cf6=%5B%22%22%2C%22%22%2C1603455527%2C%22https%3A%2F%2Fwww.baidu.com%2Flink%3Furl%3DQac46hk9YhT6S2icrwYRz-bF_bTVaE-5oVDnxcKMp0IA9FS4h20lIrzbogT_RNEeE0EmlaoJQvcE-w578iDfc_%26wd%3D%26eqid%3Da176cdb900094e26000000065f8bdfc5%22%5D; _pk_id.100001.4cf6=d7da5ff658f558d0.1587289375.48.1603455527.1603011634.; _pk_ses.100001.4cf6=*; __utma=30149280.1305261876.1596342801.1603284251.1603455527.49; __utmb=30149280.0.10.1603455527; __utmc=30149280; __utma=223695111.1437118223.1587289374.1603011421.1603455527.48; __utmb=223695111.0.10.1603455527; __utmc=223695111
    Host: movie.douban.com
    User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.80 Safari/537.36
    '''
    headers=headers_raw_to_dict(r_h)
    data_list = []
    base_url='https://movie.douban.com/celebrity/1011562/photos/?type=C&start={}&sortby=like&size=a&subtype=a'

    def fire(self):
        try:
            page = 0
            for i in range(0, 450, 30):
                logger.info("开始爬取第 %s 页" % page)
                resp=session.get(url=self.base_url.format(i),headers=self.headers,verify=False).content.decode()
                self.get_poster_url(resp)
                page += 1
                time.sleep(1)
        except Exception:
            traceback.print_exc()
    
    def get_poster_url(self,resp):
        if not os.path.exists(r'picture'):
            os.mkdir(r'picture')
        html=etree.HTML(resp)
        all_li= html.xpath("//ul[contains(@class,'poster-col3')]/li")
        for i in all_li:
            link=''.join(i.xpath("./div[@class='cover']/a/img/@src"))
            print(link)
            self.download_picture(link)

    def download_picture(self,link):
        pic = requests.get(link)
        p_name = link.split('/')[7]
        with open('picture//' + p_name, 'wb') as f:
            f.write(pic.content)

    def start(self):
        self.fire()

if __name__=='__main__':
    Spider().start()
```